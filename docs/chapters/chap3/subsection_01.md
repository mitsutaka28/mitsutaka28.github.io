[メインページ](../../index.markdown)

[章目次](./chap3.md)
## 3.1. はじめに

機械学習とは，明示的にプログラムせずに，サンプルデータからコンピュータに適切な動作を学習させる研究分野である.
そして深層学習とは，ニューラルネットワーク上に構成された機械学習アルゴリズムの一種である.
実は，深層学習の主要な構成要素のほとんどは数十年前から存在していたが，深層学習が普及したのは近年のことである.
ニューラルネットワークのアイデアは，McCulloch-Pitts Neuron（McCulloch
and Pitts，1943）が初めて紹介された1940年代に遡る.
この線形モデルは，入力情報を線形に集約することで，入力が2つのカテゴリのうちどちらのものかを判断することができる.
その後，パーセプトロン(Rosenblatt，1958)が開発された．
これによって学習サンプルを与えてパラメータを学習することができるようになった.
ニューラルネットワークの研究が再び盛り上がってきたのは1980年代のことである.
この時期の大きなブレークスルーの1つは，逆伝搬法（Rumelhart et
al.，1986年，Le Cun and Fogelman-Soulie
́，1987年）を用いて，深層ニューラルネットワークモデルの学習に成功したことである.
なお，逆伝搬法は1960年代から多くの先行研究があり，Werbosがニューラルネットワークの学習に初めて応用している（Werbos，1994）.
逆伝搬法は深層学習の時代である現代においても，深層モデルを学習するためのアルゴリズムとして主流となっている.
深層学習の研究は，近年の「ビッグデータ」と強力な計算資源の利用が可能になったことで再び流行し，かつてないほどの注目を集めた.
そしてもう一つは，高速なGPUの登場により，非常に大きなサイズの深層モデルを学習することが可能になったことである．
これによって，データ量がますます大きくなったとしてもこれらのモデルが十分に一般化できることが保証された.
この2つの利点により，様々な研究分野で深層学習技術が大成功を収め，現実世界に多大な影響を与える結果となった.
様々な応用例において，深層ニューラルネットワークは従来の手法を大差で凌駕している.

以下にいくつか具体例を紹介しよう．
深層学習は，画像認識タスクのパフォーマンスを大幅に向上させた. ImageNet
Large-Scale Visual Recognition
Challengeは，画像認識における最大のコンテストで，2010年から2017年まで毎年開催された.
2012年には，畳み込みニューラルネットワーク（CNN）が，トップ5のエラー率を26.1％から15.3％に減らすという大差で，このチャレンジで初めて優勝した（Krizhevsky
et al.，2012）.
それ以降はCNNが安定して優勝しており，誤差率はさらに3.57％まで減少している（He
et al.，2016）.

また，深層学習は音声認識システムの性能を飛躍的に向上させている（Dahl et
al.2010，Deng et al.2010，Seide et al.2011）.
深層学習技術を音声認識に導入したことで，長年停滞していたエラー率が大きく低下した.

自然言語処理の研究分野も，深層学習技術によって大きく加速されている.
LSTM（Hochreiter and
Schmidhuber，1997）などのリカレントニューラルネットワークは，機械翻訳（Sutskever
et al.，2014; Bahdanau et al.，2014）や対話システム（Vinyals and
Le，2015）などの配列対配列のタスクで広く利用されている.

グラフ深層学習の研究は深層学習に根ざしているため，基本的な深層学習の技術を理解することが不可欠である.
そこで本章では，順伝搬型ネットワーク，畳み込みネットワーク（CNN），リカレントネットワーク（RNN），オートエンコーダーなど，グラフ深層学習を研究する上で基礎となる重要な深層学習技術を簡単に紹介する.
本章では基本的な深層モデルに焦点を当てているが，後の章では変分オートエンコーダー（VAE）や敵対的生成ネットワーク（GAN）などのより高度な深層モデルに議論を広げていく.


[メインページ](../../index.markdown)

[章目次](./chap3.md)

[前の節へ](./subsection_00.md) [次の節へ](./subsection_02.md)


